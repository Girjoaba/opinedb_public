{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Hotels or Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 165\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#### hotels\n",
    "# path = '../data/london/' # path = '../data/amsterdam/'\n",
    "# query_fn = path + 'hotel_queries.txt'\n",
    "# query_groundtruth_fn = path + 'hotel_query_groundtruth.txt'\n",
    "# histogram_fn = path + 'entities_with_histograms.json'\n",
    "# w2v_fn = path + 'word2vec.model'\n",
    "# idf_fn = path + 'idf.json'\n",
    "\n",
    "# entities = json.load(open(histogram_fn))\n",
    "# queries = open(query_fn).read().splitlines()\n",
    "# query_attr = open(query_groundtruth_fn).read().splitlines()\n",
    "# model = Word2Vec.load(w2v_fn)\n",
    "# idf = json.load(open(idf_fn))\n",
    "# print(len(queries), len(query_attr))\n",
    "####\n",
    "\n",
    "#### restaurants\n",
    "path = '../data/toronto/'\n",
    "query_fn = path + 'restaurant_queries.txt'\n",
    "query_groundtruth_fn = path + 'restaurant_query_groundtruth.txt'\n",
    "histogram_fn_lp = path + 'lp_entities_with_histograms.json'\n",
    "histogram_fn_jp = path + 'jp_entities_with_histograms.json'\n",
    "w2v_fn = path + 'word2vec.model'\n",
    "idf_fn = path + 'idf.json'\n",
    "\n",
    "entities = json.load(open(histogram_fn_lp))\n",
    "entities_jp = json.load(open(histogram_fn_jp))\n",
    "for bid in entities_jp:\n",
    "    if bid not in entities:\n",
    "        entities[bid] = entities_jp[bid]\n",
    "\n",
    "queries = open(query_fn).read().splitlines()\n",
    "query_attr = open(query_groundtruth_fn).read().splitlines()\n",
    "model = Word2Vec.load(w2v_fn)\n",
    "idf = json.load(open(idf_fn))\n",
    "####\n",
    "\n",
    "def compress_queries(queries, query_attr):\n",
    "    used = set([])\n",
    "    new_queries, new_qas = [], []\n",
    "    for q, qa in zip(queries, query_attr):\n",
    "        q = q.lower()\n",
    "        if q not in used:\n",
    "            new_queries.append(q)\n",
    "            new_qas.append(qa)\n",
    "            used.add(q)\n",
    "    return new_queries, new_qas\n",
    "\n",
    "queries, query_attr = compress_queries(queries, query_attr)\n",
    "print(len(queries), len(query_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34935\n"
     ]
    }
   ],
   "source": [
    "def summary_to_str(summary):\n",
    "    marker_senti = []\n",
    "    for marker in summary:\n",
    "        phrase = marker['phrase'].lower().replace('-', ' ')\n",
    "        size = marker['size']\n",
    "        senti = marker['sum_senti'] / size\n",
    "        marker_senti.append((phrase, size, senti))\n",
    "    # sort by sentiment\n",
    "    marker_senti.sort(key=lambda x : -x[2])\n",
    "    summary_line = ' '.join(['%s : %d' % (ms[0], ms[1]) for ms in marker_senti])\n",
    "\n",
    "    # some statistics\n",
    "    sum_size = sum([ms[1] for ms in marker_senti])\n",
    "    pos_cnt = sum([ms[1] for ms in marker_senti if ms[2] >= 0])\n",
    "    neg_cnt = sum([ms[1] for ms in marker_senti if ms[2] < 0])\n",
    "    summary_line += '\\t%d\\t%d\\t%d' % (sum_size, pos_cnt, neg_cnt)\n",
    "    return summary_line\n",
    "\n",
    "phrase2vec_cache = {}\n",
    "def phrase2vec(phrase):\n",
    "    phrase = phrase.lower().replace('-', ' ')\n",
    "    if phrase in phrase2vec_cache:\n",
    "        return phrase2vec_cache[phrase]\n",
    "\n",
    "    words = gensim.utils.simple_preprocess(phrase)\n",
    "    res = np.zeros(300)\n",
    "    # sum pooling\n",
    "    for w in words:\n",
    "        if w in model.wv:\n",
    "            v = model.wv[w]\n",
    "            res += v * idf[w]\n",
    "\n",
    "    # normalize\n",
    "    norm = np.linalg.norm(res)\n",
    "    if norm > 0:\n",
    "        res /= norm\n",
    "    phrase2vec_cache[phrase] = res\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_matches(histogram, query):\n",
    "    # number of exact match\n",
    "    num_exact_match = 0\n",
    "    num_appr_match = 0\n",
    "    vec1 = phrase2vec(query)\n",
    "    for phrase in histogram:\n",
    "        vec2 = phrase2vec(phrase)\n",
    "        sim = np.dot(vec1, vec2)\n",
    "        if sim >= 0.9:\n",
    "            num_exact_match += 1\n",
    "        if sim >= 0.6:\n",
    "            num_appr_match += 1\n",
    "    return '\\t%d\\t%d' % (num_exact_match, num_appr_match)\n",
    "    \n",
    "num_lines = 0\n",
    "with open('to_be_labeled.tsv', 'w') as fout:\n",
    "    fout.write('bid\\tattr\\tquery\\tsummary\\ttotal\\tpos_cnt\\tneg_cnt\\texact_match\\tsim_match\\n')\n",
    "    for query, attr in zip(queries, query_attr):\n",
    "        for bid, entity in entities.items():\n",
    "            if 'summaries' in entity and attr in entity['summaries'] and \\\n",
    "               'histogram' in entity and attr in entity['histogram']:\n",
    "                summary = entity['summaries'][attr]\n",
    "                summary_line = summary_to_str(summary) + get_matches(entity['histogram'][attr], query)\n",
    "                fout.write('%s\\t%s\\t%s\\t' % (bid, attr, query) + summary_line + '\\n')\n",
    "                num_lines += 1\n",
    "\n",
    "print(num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_results_and_dump(input_fn, output_fn):\n",
    "    with open(input_fn) as fin:\n",
    "        labels = []\n",
    "        reader = csv.DictReader(fin)\n",
    "        for row in reader:\n",
    "            if row['label'] == '1':\n",
    "                label = 'yes'\n",
    "            else:\n",
    "                label = 'no'\n",
    "            values = [row['bid'], row['attr'], row['query'], label]\n",
    "            labels.append(values)\n",
    "            \n",
    "    json.dump(labels, open(output_fn, 'w'))\n",
    "\n",
    "label_fn = '../data/toronto_labeled.csv'\n",
    "read_results_and_dump(label_fn, path + 'labels.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase model score = 0.840404\n",
      "marker model score = 0.838384\n",
      "w2v acc :  0.745945945945946\n",
      "cooc acc :  0.654054054054054\n",
      "crowd\n",
      "food\n",
      "food\n",
      "general\n",
      "group\n",
      "menu\n",
      "vibe\n",
      "crowd\n",
      "vibe\n",
      "staff\n",
      "vibe\n",
      "food\n",
      "vibe\n",
      "food\n",
      "general\n",
      "group\n",
      "crowd\n",
      "menu\n",
      "menu\n",
      "food\n",
      "menu\n",
      "staff\n",
      "food\n",
      "menu\n",
      "vibe\n",
      "crowd\n",
      "food\n",
      "general\n",
      "vibe\n",
      "price\n",
      "general\n",
      "location\n",
      "vibe\n",
      "food\n",
      "staff\n",
      "food\n",
      "vibe\n",
      "vibe\n",
      "vibe\n",
      "price\n",
      "staff\n",
      "drink\n",
      "vibe\n",
      "vibe\n",
      "menu\n",
      "group\n",
      "menu\n",
      "food\n",
      "vibe\n",
      "vibe\n",
      "food\n",
      "vibe\n",
      "menu\n",
      "vibe\n",
      "group\n",
      "general\n",
      "vibe\n",
      "menu\n",
      "general\n",
      "menu\n",
      "menu\n",
      "menu\n",
      "food\n",
      "drink\n",
      "menu\n",
      "vibe\n",
      "drink\n",
      "staff\n",
      "vibe\n",
      "crowd\n",
      "food\n",
      "menu\n",
      "menu\n",
      "food\n",
      "staff\n",
      "crowd\n",
      "food\n",
      "general\n",
      "price\n",
      "crowd\n",
      "crowd\n",
      "menu\n",
      "vibe\n",
      "crowd\n",
      "general\n",
      "food\n",
      "vibe\n",
      "food\n",
      "food\n",
      "menu\n",
      "vibe\n",
      "price\n",
      "food\n",
      "drink\n",
      "food\n",
      "staff\n",
      "general\n",
      "vibe\n",
      "food\n",
      "crowd\n",
      "menu\n",
      "food\n",
      "crowd\n",
      "table\n",
      "vibe\n",
      "general\n",
      "price\n",
      "delivery\n",
      "food\n",
      "general\n",
      "food\n",
      "general\n",
      "food\n",
      "food\n",
      "staff\n",
      "crowd\n",
      "price\n",
      "vibe\n",
      "vibe\n",
      "food\n",
      "crowd\n",
      "food\n",
      "food\n",
      "food\n",
      "crowd\n",
      "food\n",
      "food\n",
      "price\n",
      "food\n",
      "food\n",
      "vibe\n",
      "food\n",
      "food\n",
      "vibe\n",
      "delivery\n",
      "food\n",
      "general\n",
      "food\n",
      "price\n",
      "vibe\n",
      "food\n",
      "crowd\n",
      "group\n",
      "vibe\n",
      "menu\n",
      "crowd\n",
      "staff\n",
      "group\n",
      "staff\n",
      "crowd\n",
      "vibe\n",
      "vibe\n",
      "food\n",
      "menu\n",
      "vibe\n",
      "general\n",
      "crowd\n",
      "staff\n",
      "vibe\n",
      "food\n",
      "drink\n",
      "staff\n",
      "menu\n",
      "staff\n",
      "food\n",
      "menu\n",
      "food\n",
      "food\n",
      "staff\n",
      "general\n",
      "crowd\n",
      "vibe\n",
      "menu\n",
      "drink\n",
      "food\n",
      "delivery\n",
      "food\n",
      "delivery\n",
      "vibe\n",
      "general\n",
      "staff\n",
      "crowd\n",
      "group\n",
      "group\n",
      "vibe\n",
      "combined acc :  0.745945945945946\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"opine\", \"../opine.py\")\n",
    "opinedb = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(opinedb)\n",
    "\n",
    "\n",
    "def accuracy(list1, list2):\n",
    "    N = len(list1)\n",
    "    TP = sum([list1[i] == list2[i] for i in range(N)])\n",
    "    return TP / N\n",
    "\n",
    "# run w2v\n",
    "def run_w2v():\n",
    "    simple_opine.clear_cache()\n",
    "    attributes = []\n",
    "    for query in queries:\n",
    "        attr, phrase = simple_opine.interpret(query, fallback_threshold=-1.0)\n",
    "        vec1 = simple_opine.phrase2vec(query)\n",
    "        vec2 = simple_opine.phrase2vec(phrase)\n",
    "        sim = simple_opine.cosine(vec1, vec2)\n",
    "        # print('%s\\t%s\\t%s\\t%f' % (query, attr, phrase, sim))\n",
    "        attributes.append(attr)\n",
    "\n",
    "    #for attr in attributes:\n",
    "    #    print(attr)\n",
    "    print('w2v acc : ', accuracy(attributes, query_groundtruth))\n",
    "\n",
    "# run cooc\n",
    "def run_cooc():\n",
    "    simple_opine.clear_cache()\n",
    "    attributes = []\n",
    "    for query in queries:\n",
    "        attr, phrase = simple_opine.cooc.interpret(query)\n",
    "        if attr != None:\n",
    "            vec1 = simple_opine.phrase2vec(query)\n",
    "            vec2 = simple_opine.phrase2vec(phrase)\n",
    "            sim = simple_opine.cosine(vec1, vec2)\n",
    "            # print('%s\\t%s\\t%s\\t%f' % (query, attr, phrase, sim))\n",
    "        else:\n",
    "            pass\n",
    "            # print('%s\\t%s' % (query, attr))\n",
    "        attributes.append(attr)\n",
    "\n",
    "    # for attr in attributes:\n",
    "    #     print(attr)\n",
    "    print('cooc acc : ', accuracy(attributes, query_groundtruth))\n",
    "\n",
    "# run combined\n",
    "def run_combined():\n",
    "    simple_opine.clear_cache()\n",
    "    attributes = []\n",
    "    for query in queries:\n",
    "        attr, phrase = simple_opine.interpret(query, fallback_threshold=0.8)\n",
    "        vec1 = simple_opine.phrase2vec(query)\n",
    "        vec2 = simple_opine.phrase2vec(phrase)\n",
    "        sim = simple_opine.cosine(vec1, vec2)\n",
    "        # print('%s\\t%s\\t%s\\t%f' % (query, attr, phrase, sim))\n",
    "        attributes.append(attr)\n",
    "\n",
    "    for attr in attributes:\n",
    "        print(attr)\n",
    "\n",
    "    print('combined acc : ', accuracy(attributes, query_groundtruth))\n",
    "\n",
    "def run_hotel_examples():\n",
    "    attr, phrase = simple_opine.cooc.interpret(\"for our anniversary\")\n",
    "    marker = simple_opine.get_marker(attr, phrase)\n",
    "    print(attr, ':', marker)\n",
    "\n",
    "    attr, phrase = simple_opine.cooc.interpret(\"multiple eating options\")\n",
    "    marker = simple_opine.get_marker(attr, phrase)\n",
    "    print(attr, ':', marker)\n",
    "\n",
    "    attr, phrase = simple_opine.cooc.interpret(\"kid friendly hotel\")\n",
    "    marker = simple_opine.get_marker(attr, phrase)\n",
    "    print(attr, ':', marker)\n",
    "\n",
    "\n",
    "path = '../data/toronto/'\n",
    "histogram_fn = path + 'jp_entities_with_histograms.json'\n",
    "extraction_fn = path + 'jp_restaurant_reviews_with_extractions.json'\n",
    "sentiment_fn = path + 'sentiment.json'\n",
    "word2vec_fn = path + 'word2vec.model'\n",
    "idf_fn = path + 'idf.json'\n",
    "query_label_fn = path + 'labels.json'\n",
    "selected_bids = '../data/raw_jp_restaurants.json'\n",
    "query_path = path + 'restaurant_queries.txt'\n",
    "query_groundtruth_path = path + 'restaurant_query_groundtruth.txt'\n",
    "\n",
    "\n",
    "queries = open(query_path).read().splitlines()\n",
    "query_groundtruth = open(query_groundtruth_path).read().splitlines()\n",
    "simple_opine = opinedb.SimpleOpine(histogram_fn, extraction_fn, sentiment_fn, word2vec_fn, idf_fn, query_label_fn, selected_bids)\n",
    "\n",
    "# run interpreters\n",
    "run_w2v()\n",
    "run_cooc()\n",
    "run_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v acc :  0.8432432432432433\n",
      "cooc acc :  0.6864864864864865\n",
      "crowd\n",
      "vibe\n",
      "food\n",
      "general\n",
      "group\n",
      "menu\n",
      "vibe\n",
      "crowd\n",
      "vibe\n",
      "staff\n",
      "vibe\n",
      "food\n",
      "crowd\n",
      "food\n",
      "general\n",
      "group\n",
      "crowd\n",
      "menu\n",
      "menu\n",
      "food\n",
      "menu\n",
      "staff\n",
      "food\n",
      "menu\n",
      "vibe\n",
      "crowd\n",
      "food\n",
      "general\n",
      "location\n",
      "price\n",
      "general\n",
      "location\n",
      "vibe\n",
      "food\n",
      "staff\n",
      "food\n",
      "vibe\n",
      "vibe\n",
      "vibe\n",
      "price\n",
      "staff\n",
      "drink\n",
      "crowd\n",
      "vibe\n",
      "menu\n",
      "group\n",
      "menu\n",
      "food\n",
      "vibe\n",
      "vibe\n",
      "food\n",
      "vibe\n",
      "menu\n",
      "crowd\n",
      "group\n",
      "general\n",
      "vibe\n",
      "menu\n",
      "food\n",
      "menu\n",
      "menu\n",
      "menu\n",
      "food\n",
      "drink\n",
      "menu\n",
      "vibe\n",
      "drink\n",
      "staff\n",
      "vibe\n",
      "crowd\n",
      "food\n",
      "menu\n",
      "menu\n",
      "food\n",
      "staff\n",
      "crowd\n",
      "food\n",
      "general\n",
      "price\n",
      "crowd\n",
      "crowd\n",
      "menu\n",
      "vibe\n",
      "crowd\n",
      "general\n",
      "food\n",
      "vibe\n",
      "food\n",
      "food\n",
      "menu\n",
      "vibe\n",
      "price\n",
      "price\n",
      "drink\n",
      "food\n",
      "staff\n",
      "general\n",
      "vibe\n",
      "food\n",
      "crowd\n",
      "menu\n",
      "food\n",
      "crowd\n",
      "location\n",
      "vibe\n",
      "general\n",
      "price\n",
      "delivery\n",
      "food\n",
      "general\n",
      "food\n",
      "general\n",
      "menu\n",
      "food\n",
      "staff\n",
      "crowd\n",
      "price\n",
      "vibe\n",
      "vibe\n",
      "food\n",
      "crowd\n",
      "food\n",
      "vibe\n",
      "food\n",
      "crowd\n",
      "food\n",
      "price\n",
      "price\n",
      "food\n",
      "food\n",
      "vibe\n",
      "food\n",
      "food\n",
      "vibe\n",
      "delivery\n",
      "food\n",
      "general\n",
      "food\n",
      "price\n",
      "vibe\n",
      "food\n",
      "crowd\n",
      "group\n",
      "vibe\n",
      "menu\n",
      "crowd\n",
      "staff\n",
      "group\n",
      "staff\n",
      "crowd\n",
      "vibe\n",
      "vibe\n",
      "food\n",
      "menu\n",
      "vibe\n",
      "general\n",
      "crowd\n",
      "staff\n",
      "vibe\n",
      "food\n",
      "drink\n",
      "staff\n",
      "menu\n",
      "staff\n",
      "food\n",
      "menu\n",
      "food\n",
      "food\n",
      "staff\n",
      "general\n",
      "crowd\n",
      "vibe\n",
      "menu\n",
      "drink\n",
      "general\n",
      "delivery\n",
      "food\n",
      "delivery\n",
      "vibe\n",
      "general\n",
      "staff\n",
      "crowd\n",
      "group\n",
      "group\n",
      "vibe\n",
      "combined acc :  0.8432432432432433\n"
     ]
    }
   ],
   "source": [
    "queries = open(query_path).read().splitlines()\n",
    "query_groundtruth = open(query_groundtruth_path).read().splitlines()\n",
    "\n",
    "# def run_cooc():\n",
    "#     simple_opine.clear_cache()\n",
    "#     attributes = []\n",
    "#     for query in queries:\n",
    "#         attr, phrase = simple_opine.cooc.interpret(query)\n",
    "#         if attr != None:\n",
    "#             vec1 = simple_opine.phrase2vec(query)\n",
    "#             vec2 = simple_opine.phrase2vec(phrase)\n",
    "#             sim = simple_opine.cosine(vec1, vec2)\n",
    "#             # print('%s\\t%s\\t%s\\t%f' % (query, attr, phrase, sim))\n",
    "#         else:\n",
    "#             pass\n",
    "#             # print('%s\\t%s' % (query, attr))\n",
    "#         attributes.append(attr)\n",
    "\n",
    "#     for attr in attributes:\n",
    "#         print(attr)\n",
    "#     print('cooc acc : ', accuracy(attributes, query_groundtruth))\n",
    "\n",
    "run_w2v()\n",
    "run_cooc()\n",
    "run_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vibe : quiet place romantic dinners 0.8485417098190925\n"
     ]
    }
   ],
   "source": [
    "# attr, phrase = simple_opine.cooc.interpret(\"tasty food\")\n",
    "simple_opine.clear_cache()\n",
    "query = ''\n",
    "attr, phrase = simple_opine.cooc.interpret(query, debug=False)\n",
    "# attr, phrase = simple_opine.interpret(query)\n",
    "vec1 = simple_opine.phrase2vec(query)\n",
    "vec2 = simple_opine.phrase2vec(phrase)\n",
    "sim = simple_opine.cosine(vec1, vec2)\n",
    "# attr, phrase = simple_opine.interpret(\"kid friendly\")\n",
    "\n",
    "marker = simple_opine.get_marker(attr, phrase)\n",
    "print(attr, ':', marker, phrase, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_in_review(ext, text):\n",
    "    tokens = ext['entity'].split(' ') + ext['predicate'].split(' ')\n",
    "    for token in tokens:\n",
    "        if token not in text:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for (i, review) in enumerate(reviews):\n",
    "    text = review['text']\n",
    "    new_extractions = []\n",
    "    for ext in review['extractions']:\n",
    "        if not ext_in_review(ext, text):\n",
    "            found = False\n",
    "            for dist in range(1, 20):\n",
    "                for sign in [1, -1]:\n",
    "                    if i + dist * sign >= 0 and i + dist * sign < len(reviews) and \\\n",
    "                       ext_in_review(ext, reviews[i + dist * sign]['text']):\n",
    "                        reviews[i + dist*sign]['extractions'].append(ext)\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "        else:\n",
    "            new_extractions.append(ext)\n",
    "    review['extractions'] = new_extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(reviews, open(path + 'restaurant_reviews_with_extractions.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_subset(entity_fn, histogram_fn, extraction_fn, output_histogram_fn, output_extraction_fn):\n",
    "    raw_entities = json.load(open(entity_fn))\n",
    "    bids = []\n",
    "    for entity in raw_entities:\n",
    "        bids.append(entity['business_id'])\n",
    "        \n",
    "    entities = json.load(open(histogram_fn))\n",
    "    entities = { bid : entities[bid] for bid in bids}\n",
    "    json.dump(entities, open(output_histogram_fn, 'w'))\n",
    "    \n",
    "    bids = set(bids)\n",
    "    reviews = json.load(open(extraction_fn))\n",
    "    reviews = [review for review in reviews if review['business_id'] in bids]\n",
    "    json.dump(reviews, open(output_extraction_fn, 'w'))\n",
    "\n",
    "path = '../data/toronto/'\n",
    "histogram_fn = path + 'entities_with_histograms.json'\n",
    "extraction_fn = path + 'restaurant_reviews_with_extractions.json'\n",
    "output_histogram_fn = path + 'lp_entities_with_histograms.json'\n",
    "output_extraction_fn = path + 'lp_restaurant_reviews_with_extractions.json'\n",
    "\n",
    "get_subset('../data/raw_lp_restaurants.json', \n",
    "           histogram_fn, \n",
    "           extraction_fn, \n",
    "           output_histogram_fn, \n",
    "           output_extraction_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
